{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvC1CS6RwWuT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLsQVR8x0r4Q"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ca6oSzL90vC5"
   },
   "outputs": [],
   "source": [
    "# train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYxhKc79A93M"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "train['DOB'] = pd.to_datetime(train.DOB)\n",
    "train['month'] = train['DOB'].dt.month\n",
    "# train['dayofweek'] = train['DOB'].dt.dayofweek\n",
    "train['year'] = train['DOB'].dt.year\n",
    "# train['day'] = train['DOB'].dt.day\n",
    "# train['dayofyear'] = train['DOB'].dt.dayofyear\n",
    "# train['weekofyear'] = train['DOB'].dt.weekofyear\n",
    "\n",
    "\n",
    "test['DOB'] = pd.to_datetime(test.DOB)\n",
    "test['month'] = test['DOB'].dt.month\n",
    "# test['dayofweek'] = test['DOB'].dt.dayofweek\n",
    "test['year'] = test['DOB'].dt.year\n",
    "# test['day'] = test['DOB'].dt.day\n",
    "# test['dayofyear'] = test['DOB'].dt.dayofyear\n",
    "# test['weekofyear'] = test['DOB'].dt.weekofyear\n",
    "\n",
    "train.drop(['DOB'],axis=1,inplace=True)\n",
    "test.drop(['DOB'],axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8odl28qSbyi9"
   },
   "outputs": [],
   "source": [
    "for index,row in train.iterrows(): \n",
    "    if(row['lump_sum_pay']>20000):\n",
    "        train.drop(index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9ECl4qk1td0"
   },
   "outputs": [],
   "source": [
    "train['train']=1\n",
    "test['train']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "xtbz7W1e83s4",
    "outputId": "f8906efb-2065-43d9-d9b6-2be46a452968"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freakcap/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "temp=pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTpAyDfPCm1u"
   },
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "# temp['location'] = labelencoder.fit_transform(temp['location'])\n",
    "temp['employer'] = labelencoder.fit_transform(temp['employer'])\n",
    "# temp['pension'] = labelencoder.fit_transform(temp['pension'])\n",
    "# temp['employer_url'] = labelencoder.fit_transform(temp['employer_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEdJTiz63YoA"
   },
   "outputs": [],
   "source": [
    "temp['lump_sum_pay'].fillna(temp.groupby('employer')['lump_sum_pay'].transform('mean'), inplace=True)\n",
    "# temp['location'].fillna(temp.groupby('employer')['location'].transform('value_counts'), inplace=True)\n",
    "temp['retirement_cost_covered'].fillna(temp.groupby('employer')['retirement_cost_covered'].transform('mean'), inplace=True)\n",
    "# temp['pension'].fillna(temp.groupby('employer')['lump_sum_pay'].transform('mean'), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "yfNQQ-b15OX8",
    "outputId": "8e484374-83d0-4323-ab49-0fb7cba3e10a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freakcap/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "train = temp[temp['train']==1]\n",
    "test = temp[temp['train']==0]\n",
    "train.drop(['train'],axis=1,inplace=True)\n",
    "test.drop(['train'],axis=1,inplace=True)\n",
    "test.drop(['total_wages'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "QHcVZ0AbAmkT",
    "outputId": "2e23780e-d0f5-4c4e-ce17-15d141767144"
   },
   "outputs": [],
   "source": [
    "train.drop(['location'],axis=1,inplace=True)\n",
    "train.drop(['pension'],axis=1,inplace=True)\n",
    "train.drop(['employer_url'],axis=1,inplace=True)\n",
    "train.drop(['Id'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "test.drop(['location'],axis=1,inplace=True)\n",
    "test.drop(['pension'],axis=1,inplace=True)\n",
    "test.drop(['employer_url'],axis=1,inplace=True)\n",
    "\n",
    "Id = test['Id']\n",
    "\n",
    "test.drop(['Id'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "dPPo7cgXAqPG",
    "outputId": "b820479e-9e4c-4252-881a-683b52c61bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22955 entries, 0 to 22999\n",
      "Data columns (total 11 columns):\n",
      "employer                   22955 non-null int64\n",
      "health_benefits            22955 non-null float64\n",
      "lump_sum_pay               22955 non-null float64\n",
      "max_pos_salary             22955 non-null float64\n",
      "min_pos_salary             22955 non-null float64\n",
      "month                      22955 non-null int64\n",
      "other_pay                  22955 non-null float64\n",
      "overtime_pay               22955 non-null float64\n",
      "retirement_cost_covered    22955 non-null float64\n",
      "total_wages                22955 non-null float64\n",
      "year                       22955 non-null int64\n",
      "dtypes: float64(8), int64(3)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "b02-48qzJDF9",
    "outputId": "29160adf-1e74-4fab-a9fd-2a720c5f64d0"
   },
   "outputs": [],
   "source": [
    "for index,row in train.iterrows(): \n",
    "    if(row['min_pos_salary']>100000 or row['total_wages']>250000):\n",
    "        train.drop(index,inplace=True)\n",
    "    elif(row['max_pos_salary']>350000):\n",
    "        train.drop(index,inplace=True)\n",
    "    elif(row['overtime_pay']>20000):\n",
    "        train.drop(index,inplace=True)\n",
    "    elif(row['other_pay']>40000):\n",
    "        train.drop(index,inplace=True)\n",
    "    elif(row['retirement_cost_covered']>500):\n",
    "        train.drop(index,inplace=True)\n",
    "    elif(row['health_benefits']<-5000):\n",
    "        train.drop(index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooO1leZ9duiP"
   },
   "outputs": [],
   "source": [
    "y = train[\"total_wages\"]\n",
    "\n",
    "X = train.drop([\"total_wages\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjk72sNgeKcC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train , x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "X_train = x_train\n",
    "X_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "WGlDzI2MegRh",
    "outputId": "c28972fc-9e79-4f53-9cbb-fcae60d13499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 218, 236, 254, 272, 290, 309, 327, 345, 363, 381, 400, 418, 436, 454, 472, 490, 509, 527, 545, 563, 581, 600, 618, 636, 654, 672, 690, 709, 727, 745, 763, 781, 800, 818, 836, 854, 872, 890, 909, 927, 945, 963, 981, 1000, 1018, 1036, 1054, 1072, 1090, 1109, 1127, 1145, 1163, 1181, 1200, 1218, 1236, 1254, 1272, 1290, 1309, 1327, 1345, 1363, 1381, 1400, 1418, 1436, 1454, 1472, 1490, 1509, 1527, 1545, 1563, 1581, 1600, 1618, 1636, 1654, 1672, 1690, 1709, 1727, 1745, 1763, 1781, 1800, 1818, 1836, 1854, 1872, 1890, 1909, 1927, 1945, 1963, 1981, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 100)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs=-1)# Fit the random search model\n",
    "rf_random.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRLeNjdOez_n"
   },
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "datawiz19_R2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
